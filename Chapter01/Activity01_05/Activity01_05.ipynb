{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Performance of a random agent\n",
    "This activity will guide you through an important phase of every RL experiment: the measurement of performances and the design of agents. You have to design a random agent using a Python class to modularize and keep the agent independent from the main loop. After that, you have to measure the mean and the variance of the Discounted Return using a batch of 100 episodes. You can use every environment you want, taking into account that the agentâ€™s action should be compatible with the environment. You can design two different types of agent for discrete action spaces and for continuous action spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Abstract class representing the agent\n",
    "Init with the action space and the function pi returning the action\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, action_space: gym.spaces.Space):\n",
    "        \"\"\"\n",
    "        Constructor of the agent class.\n",
    "        \n",
    "        Args:\n",
    "            action_space (gym.spaces.Space): environment action space\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"This class cannot be instantiated.\")\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def pi(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Agent's policy.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state\n",
    "        \n",
    "        Returns:\n",
    "            The selected action\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousAgent(Agent):\n",
    "    def __init__(self, action_space: gym.spaces.Space, seed=46):\n",
    "        # setup seed\n",
    "        np.random.seed(seed)\n",
    "        # check the action space type\n",
    "        if not isinstance(action_space, gym.spaces.Box):\n",
    "            raise ValueError(\"This is a Continuous Agent pass as input a Box Space.\")\n",
    "\n",
    "        # initialize the distribution according to the action space type\n",
    "        if (action_space.low == -np.inf) and (action_space.high == np.inf):\n",
    "            # the distribution is a normal distribution\n",
    "            self._pi = lambda: np.random.normal(loc=0, scale=1, size=action_space.shape)\n",
    "            return\n",
    "        if (action_space.low != -np.inf) and (action_space.high != np.inf):\n",
    "            # the distribution is a uniform distribution\n",
    "            self._pi = lambda: np.random.uniform(\n",
    "                low=action_space.low, high=action_space.high, size=action_space.shape\n",
    "            )\n",
    "            return\n",
    "        if action_space.low == -np.inf:\n",
    "            # negative exponential distribution\n",
    "            self._pi = (\n",
    "                lambda: -np.random.exponential(size=action_space.shape)\n",
    "                + action_space.high\n",
    "            )\n",
    "            return\n",
    "        if action_space.high == np.inf:\n",
    "            # exponential distribution\n",
    "            self._pi = (\n",
    "                lambda: np.random.exponential(size=action_space.shape)\n",
    "                + action_space.low\n",
    "            )\n",
    "            return\n",
    "\n",
    "    def pi(self, observation: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Policy: simply call the internal _pi().\n",
    "        \n",
    "        This is a random agent so the action is independent from the observation.\n",
    "        For real agents the action depends on the observation.\n",
    "        \"\"\"\n",
    "        return self._pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteAgent(Agent):\n",
    "    def __init__(self, action_space: gym.spaces.Space, seed=46):\n",
    "        # setup seed\n",
    "        np.random.seed(seed)\n",
    "        # check the action space type\n",
    "        if not isinstance(action_space, gym.spaces.Discrete):\n",
    "            raise ValueError(\"This is a Discrete Agent pass as input a Discrete Space.\")\n",
    "\n",
    "        # initialize the distribution according to the action space n attribute\n",
    "        # the distribution is a uniform distribution\n",
    "        self._pi = lambda: np.random.randint(low=0, high=action_space.n)\n",
    "\n",
    "    def pi(self, observation: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Policy: simply call the internal _pi().\n",
    "        \n",
    "        This is a random agent so the action is independent from the observation.\n",
    "        For real agents the action depends on the observation.\n",
    "        \"\"\"\n",
    "        return self._pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function\n",
    "Utility function to initialize the correct agent based on the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent(action_space: gym.spaces.Space, seed=46):\n",
    "    \"\"\"\n",
    "    Returns the correct agent based on the action space type\n",
    "    \"\"\"\n",
    "    if isinstance(action_space, gym.spaces.Discrete):\n",
    "        return DiscreteAgent(action_space, seed)\n",
    "    if isinstance(action_space, gym.spaces.Box):\n",
    "        return ContinuousAgent(action_space, seed)\n",
    "    raise ValueError(\n",
    "        \"Only Box spaces or Discrete Spaces are allowed, check the action space of the environment\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Name\n",
    "env_name = \"CartPole-v0\"\n",
    "# Number of episodes\n",
    "episodes = 10\n",
    "# Number of Timesteps of each episodes\n",
    "timesteps = 100\n",
    "# Discount factor\n",
    "gamma = 1.0\n",
    "# seed environment\n",
    "seed = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to show the environment in a notebook\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Number: 0, Timesteps: 27, Return: 28.0\n",
      "Episode Number: 1, Timesteps: 9, Return: 10.0\n",
      "Episode Number: 2, Timesteps: 13, Return: 14.0\n",
      "Episode Number: 3, Timesteps: 16, Return: 17.0\n",
      "Episode Number: 4, Timesteps: 31, Return: 32.0\n",
      "Episode Number: 5, Timesteps: 10, Return: 11.0\n",
      "Episode Number: 6, Timesteps: 14, Return: 15.0\n",
      "Episode Number: 7, Timesteps: 11, Return: 12.0\n",
      "Episode Number: 8, Timesteps: 10, Return: 11.0\n",
      "Episode Number: 9, Timesteps: 30, Return: 31.0\n",
      "Statistics on Return: Average: 18.1, Variance: 68.89000000000001\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env.seed(seed)\n",
    "# the last argument is needed to record all episodes\n",
    "# otherwise gym would record only some of them\n",
    "# The monitor saves the episodes inside the folder ./gym-results\n",
    "env = wrappers.Monitor(\n",
    "    env, \"./gym-results\", force=True, video_callable=lambda episode_id: True\n",
    ")\n",
    "\n",
    "agent = make_agent(env.action_space, seed)\n",
    "\n",
    "# list of returns\n",
    "episode_returns = []\n",
    "\n",
    "# loop for the episodes\n",
    "for episode_number in range(episodes):\n",
    "    # here we are inside an episode\n",
    "\n",
    "    # reset cumulated gamma\n",
    "    gamma_cum = 1\n",
    "\n",
    "    # return of the current episode\n",
    "    episode_return = 0\n",
    "\n",
    "    # the reset function resets the environment and returns\n",
    "    # the first environment observation\n",
    "    observation = env.reset()\n",
    "\n",
    "    # loop for the given number of timesteps or\n",
    "    # until the episode is terminated\n",
    "    for timestep_number in range(timesteps):\n",
    "\n",
    "        # render the environment\n",
    "        # env.render()\n",
    "\n",
    "        # select the action\n",
    "        action = agent.pi(observation)\n",
    "\n",
    "        # apply the selected action by calling env.step\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        # increment the return\n",
    "        episode_return += reward * gamma_cum\n",
    "\n",
    "        # update the value of cumulated discount factor\n",
    "        gamma_cum = gamma_cum * gamma\n",
    "\n",
    "        # if done the episode is terminated, we have to reset\n",
    "        # the environment\n",
    "        if done:\n",
    "            print(\n",
    "                f\"Episode Number: {episode_number}, Timesteps: {timestep_number}, Return: {episode_return}\"\n",
    "            )\n",
    "            # break from the timestep loop\n",
    "            break\n",
    "\n",
    "    episode_returns.append(episode_return)\n",
    "\n",
    "# close the environment\n",
    "env.close()\n",
    "\n",
    "# Calculate return statistics\n",
    "avg_return = np.mean(episode_returns)\n",
    "std_return = np.std(episode_returns)\n",
    "var_return = std_return ** 2  # variance is std^2\n",
    "\n",
    "print(f\"Statistics on Return: Average: {avg_return}, Variance: {var_return}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "Let's render the episodes inside a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the episodes\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "episodes_to_watch = 1\n",
    "for episode in range(episodes_to_watch):\n",
    "    video = io.open(\n",
    "        f\"./gym-results/openaigym.video.{env.file_infix}.video{episode:06d}.mp4\", \"r+b\"\n",
    "    ).read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    display(\n",
    "        HTML(\n",
    "            data=\"\"\"\n",
    "        <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>\"\"\".format(\n",
    "                encoded.decode(\"ascii\")\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the episode duration is not too long, this is because the actions are taken at random, thus the pole falls after some timesteps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
