{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisite:** OpenAI Baselines has to be installed for this Exercise to work. See section 4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import all required modules from OpenAI baselines and Tensorflow to use PPO algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ppo2.ppo2 import learn\n",
    "from baselines.ppo2 import defaults\n",
    "from baselines.common.vec_env import VecEnv, VecFrameStack\n",
    "from baselines.common.cmd_util import make_vec_env, make_env\n",
    "from baselines.common.models import register\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define and register a custom Convolutional Neural Network for the policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register(\"custom_cnn\")\n",
    "def custom_cnn():\n",
    "    def network_fn(input_shape, **conv_kwargs):\n",
    "        \"\"\"\n",
    "        Custom CNN\n",
    "        \"\"\"\n",
    "        print('input shape is {}'.format(input_shape))\n",
    "        x_input = tf.keras.Input(shape=input_shape, dtype=tf.uint8)\n",
    "        h = x_input\n",
    "        h = tf.cast(h, tf.float32) / 255.\n",
    "        \n",
    "        h = tf.keras.layers.Conv2D(filters=32, kernel_size=8, strides=4, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h)\n",
    "        h2 = tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h)\n",
    "        h3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h2)        \n",
    "        h3 = tf.keras.layers.Flatten()(h3)\n",
    "        h3 = tf.keras.layers.Dense(units=512, name='fc1', activation='relu')(h3)\n",
    "        \n",
    "        network = tf.keras.Model(inputs=[x_input], outputs=[h3])\n",
    "        network.summary()\n",
    "        return network\n",
    "\n",
    "    return network_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a function to build the environment in the format required by OpenAI baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env(env_id, env_type):\n",
    "\n",
    "    if env_type in {'atari', 'retro'}:\n",
    "        env = make_vec_env(env_id, env_type, 1, None, gamestate=None, reward_scale=1.0)\n",
    "        env = VecFrameStack(env, 4)\n",
    "\n",
    "    else:\n",
    "        env = make_vec_env(env_id, env_type, 1, None, reward_scale=1.0, flatten_dict_observations=True)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Build the `PongNoFrameskip-v4` environment, choose policy network parameters and train it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 'PongNoFrameskip-v0'\n",
    "env_type = 'atari'\n",
    "print(\"Env type = \", env_type)\n",
    "\n",
    "env = build_env(env_id, env_type)\n",
    "\n",
    "model = learn(network=\"custom_cnn\", env=env, total_timesteps=2e7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the trained agent in the environment and print the cumulative reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "if not isinstance(env, VecEnv):\n",
    "    obs = np.expand_dims(np.array(obs), axis=0)\n",
    "\n",
    "episode_rew = 0\n",
    "    \n",
    "while True:\n",
    "    actions, _, state, _ = model.step(obs)\n",
    "    obs, reward, done, info = env.step(actions.numpy())\n",
    "    if not isinstance(env, VecEnv):\n",
    "        obs = np.expand_dims(np.array(obs), axis=0)\n",
    "    env.render()\n",
    "    print(\"Reward = \", reward)\n",
    "    episode_rew += reward\n",
    "    \n",
    "    if done:\n",
    "        print('Episode Reward = {}'.format(episode_rew))\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the built-in OpenAI baseline `run` script to train PPO on `PongNoFrameskip-v0` environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=2e7 --save_path=./models/Pong_20M_ppo2 --log_path=./logs/Pong/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the built-in OpenAI Baseline `run` script to run the trained model on `PongNoFrameskip-v0` environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=0 --load_path=./models/Pong_20M_ppo2 --play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the pretrained weights to see the trained agent in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O pong_20M_ppo2.tar.gz https://github.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/blob/master/Chapter04/pong_20M_ppo2.tar.gz?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvzf pong_20M_ppo2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=0 --load_path=./pong_20M_ppo2 --play"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
